**하둡 책 정리 특징**
- _하둡 관련 발표 PPT 개념으로 작성되어, 말투가 이상하거나 일부 내용 생략이 있을 수 있습니다._

-----

# Part 1 : 하둡 기초
## Chapter 1) 하둡과의 만남

### 하둡이 필요한 이유 : 빅데이터 시대! 근데 문제는?

- 하드 디스크의 용량은 매우 증가 → 그러나 **데이터를 읽고 쓰는 그 속도에 미치지 못함**!
- 심지어 *단일 디스크의 경우 읽고, 쓰기 느림* → 그러면 100개의 디스크에 1/100 씩 데이터를 저장하면?
    - 데이터셋 100개를 **나눠 저장하고, 서로 공유**하면 좋겠다!
    - 문제점
        1. 하드웨어 많이 쓰면 **장애 발생 확률도 당연히 높아짐**
        2. 분할된 **데이터를 어떤 식으로든 결합**할 필요가 있음
- (앗, 그리고 하둡은 **범용 하드웨어에서 실행되고, 오픈 소스** 라 저렴합니다 ^^)

### 맵리듀스

- 맵리듀스 = **일괄 질의 처리기, 전체 데이터 대상으로 비정형 쿼리 수행**
    - 비정형 쿼리 : One-time성 작업에 대해 필요한걸 그때그때 현업 사용자가 직접 DB에 Query하는 SQL 형태
    - 아, 근데 대화형 분석 X 입니다. 왜냐하면 보통 **1분 이상 걸려서요.**

### 그러면 하둡은 분산 일괄 질의 처리 시스템이자 플랫폼인가요? 아니오!

- 그러나 지금은 HDFS와 맵리듀스 뿐만이 아니라, 수많은 에코 시스템 프로젝트를 가리킵니다.
    - 즉, 지금은 꼭 일괄 질의 처리기를 뜻하지는 않습니다!
    - 아파치 재단에서 관리하는 수많은 에코 시스템 프로젝트들 예시 : HBase, Hive, Pig 등
        - 하둡 (기반) 에코시스템에서 가능해진 것들
            - **대화형 SQL** : 장기 실행 전용 데몬 임팔라(Impala), 컨테이너 재사용하는 분산 쿼리 엔진 사용 → 하둡 기반 SQL 쿼리를 실행할 때, 빠른 응답속도를 가짐
            - **반복 처리** : 머신러닝처럼 반복 연산을 하는 경우, 메모리에 임시 작업 데이터셋 저장이 유리
            → 맵리듀스 아키텍처의 경우는 안되지만, 스파크는 가능
            - **스트림 처리** : 실시간으로 실행되고, 경계 없는 스트림 데이터를 분석해서 그 결과를 하둡 저장소나 외부 시스템으로 보냄
            - **검색** : 솔라 검색 플롯폼 → 문서를 색인해 HDFS 에 저장하고, 그 색인을 기반으로 검색 데이터 제공

### 다른 시스템과의 비교

<details>
<summary>관계형 DB 관리 시스템 VS 하둡</summary>

- 목록
    - 왜 여러 디스크를 가진 DB 를 써서 대규모 분석을 수행하진 않는 걸까?
    → *탐색 시간은 전송 속도보다 발전이 더디다*
    - 맵리듀스는 비정형 분석과 같이 일괄 처리 방식으로 데이터셋을 분석할 때 유리!
        - 기가바이트로 저장
        - 무결성 낮음
        - 읽기 기준 스키마
        - 확장 선형
    - RDBMS 는 상대적으로 작은 데이터셋을 빠른 시간 내에 추출하교 변경하기 위해 데이터를 색인하는 편.
        - 페타바이트로 저장
        - 무결성 높음
        - 쓰기 기준 스키마
        - 확장 비선형
    - 그렇긴 한데 요즘은 좀 경계가 불분명해지고 있는듯 ㅎㅎ
    - 굳이 차이를 지적하자면!
        - 하둡 : 정형 데이터, RDBMS : 비정형 데이터
        - 하둡 : 비지역 연산으로 읽고, 고속의 순차적 읽기와 쓰기를 수행하기 때문에 정규화 X, RDBMS : 정규화
        - 웹 서버 로그 = 정규화 되지 않은 데이터 로그
        - 하둡 : 모델 데이터 크기에 따라 선형적으로 확장, RDBMS : 그렇지 않음.

</details>

<details>
<summary>그리드 컴퓨팅 VS 하둡</summary>

- 목록
    - 그리드 컴퓨팅은 (MPI 같은) API 를 이용해서 이미 대규모 데이터를 처리하고 있다!
    - 그리드 컴퓨팅
        - 대용량 데이터에 접근해야하는 경우, 네트워크 대역폭 때문에 병목 현상이 생기고 쉬는 계산 노드가 생긴다.
        - 또한 MPI 는 사용자가 저수준 레벨까지 확실하게 이해하고 프로그래밍해서 사용할 필요가 있다.
        - 체크포인트와 장애 복구 지점을 명확하게 사용자가 표시해야함
    - 하둡
        - 계산 노드와 데이터를 같이 배치한다. 따라서 데이터가 로컬에 있다! (와 네트워크로 가져올 필요 없어!)
        - 하둡은 그런 거 몰라도 되고 맵리듀스의 키-값 쌍만 이해하면 된다
        - 맵리듀스같은 분산 처리 프레임워크는 실패한 태스크를 감지해서 장애가 없는 머신에 다시 배치할 수 있음. 이게 가능한 이유는 맵리듀스가 태스크간 상호의존이 없는 **비공유** 아키텍처이기 때문이다.
        - 물론 실패한 맵 보다는 실패한 리듀스에 집중한다. 자세한 건 맵리듀스 파트에서 설명하니 그 때 볼 것.
    - 계산 중심의 대용량 데이터 처리는 이쪽이 낫고, 데이터가 큰 거면 저쪽이 낫다!
</details>

<details>
<summary>자발적 컴퓨팅 VS 하둡</summary>

- 목록
    - 자발적 컴퓨팅은 청크라는 작업 단위로 해결할 문제들을 분리하고, 이를 분석하기위해 전 세계의 컴퓨터로 보낸다. 그리고 완료되면 서버로 보낸다. (물론 트롤을 막기 위해 각 작업 단위는 두, 세 개의 컴에 보냄)
    - 비슷해보이지만 자발적 컴퓨팅은 CPU 중심적이고, 작업 단위를 전송하는 시간이 계산하는 시간보다 빠르니까 전 세계의 컴에서 계산하는데 적합하다. 자원봉사자들이 기부한 것은 CPU 사이클이다.
    - 맵리듀스는 매우 높은 네트워크 대역폭을 가진 단일 데이터 센터에서 수 분 또는 수 시간 내에 Job 을 분석하게 되어 있다. 자발적 컴퓨팅은 당연히 연결 속도가 가변적이고, 데이터 지역성이 신뢰할 수 없는 로컬 컴퓨터에서 오래 걸리는 연산을 한다.
</details>

### 아파치 하둡의 짧은 역사

- 하둡 이름의 유래 : 하둡의 창시자 *더그 커팅* 의 딸이 노란 봉제 코끼리 인형에 붙여준 이름. 짧고 맞춤법과 발음이 쉽고, 다른 곳에서 안 쓰는 이름이라 붙였다고 합니다.
- 개발 역사
    - 웹 검색 엔진인 아파치 너치의 하위 프로젝트로 시작
    - GFS라는 구글 분산 파일 시스템이 발표되었고, 큰 도움을 얻음 (웹 크롤링과 색인 과정에서 발생하는 파일들 저장 밑 관리 가능)
    - NDFS 라는 너치 분산 시스템 오픈 소스로 개발 시작
    - 구글이 맵리듀스 논문 발표 (2004년!)
    - 너치의 맵리듀스, NDFS 가 따로 분리되어 오픈 소스로 개발 시작 → 이 것이 하둡!
    - 테라바이트 데이터 정렬 신기록을 세운 하둡! 암튼 하둡 짱짱맨
